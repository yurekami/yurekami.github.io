<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://yurekami.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://yurekami.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-14T15:51:42+00:00</updated><id>https://yurekami.github.io/feed.xml</id><title type="html">blank</title><subtitle>First principles thinking. Computational modeling. Mathematics. </subtitle><entry><title type="html">The Mathematical Metabolism: Why AI Solves Problems But Doesn’t Create Mathematics</title><link href="https://yurekami.github.io/blog/2026/mathematical-metabolism/" rel="alternate" type="text/html" title="The Mathematical Metabolism: Why AI Solves Problems But Doesn’t Create Mathematics"/><published>2026-02-14T00:00:00+00:00</published><updated>2026-02-14T00:00:00+00:00</updated><id>https://yurekami.github.io/blog/2026/mathematical-metabolism</id><content type="html" xml:base="https://yurekami.github.io/blog/2026/mathematical-metabolism/"><![CDATA[<p>In a recent announcement, the Google DeepMind team presented their Aletheia system, which reportedly solved four open Erdős conjectures — a noteworthy result, particularly given the historical difficulty of many problems in the Erdős corpus. The solve rate of approximately 0.6% on a bank of 700 Erdős problems is, on first glance, both impressive (four genuine solutions to long-standing open problems) and informative (the 99.4% failure rate telling us something about the current limits of the approach).</p> <p>I wanted to record some thoughts on this work, not so much about the specific results (which I have not fully verified), but about a broader question that the work brings into focus: <strong>what is the distinction between an AI system that proves theorems and one that does mathematics?</strong> It turns out that the answer, while somewhat philosophical, has concrete architectural implications that I find interesting.</p> <hr/> <h2 id="1-the-architecture-and-claims">1. The architecture and claims</h2> <p>The Aletheia system follows what has by now become the standard generator-verifier paradigm for AI-for-mathematics, going back at least to AlphaProof and related systems:</p> <pre><code class="language-mermaid">flowchart LR
    A[Problem Input] --&gt; B[Generator\nGemini Deep Think]
    B --&gt; C[Candidate Proof]
    C --&gt; D[Verifier\nGemini + Heuristics]
    D --&gt; E[Output Solution]
    D --&gt;|Minor Fix| B
    D --&gt;|Critical Flaw| F[Discard &amp; Retry]
    D --&gt;|Ambiguous| G[Human Expert]

    style B fill:#1e3a5f,stroke:#58a6ff,color:#c9d1d9
    style D fill:#451a03,stroke:#f0883e,color:#c9d1d9
    style E fill:#064e3b,stroke:#3fb950,color:#c9d1d9
</code></pre> <div class="caption"> Generator-Verifier Architecture — the standard pipeline for AI-for-math systems since AlphaProof. </div> <p>Roughly speaking, the announcement makes five claims of varying strength:</p> <ol> <li><strong>Autonomous solving</strong> — the system independently solved four open Erdős conjectures.</li> <li><strong>Scaling beyond competition mathematics</strong> — this extends AI reasoning beyond olympiad-level problems to research-level mathematics.</li> <li><strong>Scaffold effectiveness</strong> — the generator-verifier feedback loop provides an effective reasoning scaffold.</li> <li><strong>Cross-domain transfer</strong> — the capabilities generalize across different mathematical domains.</li> <li><strong>Responsible taxonomy</strong> — solutions are categorized by the level of human involvement required.</li> </ol> <p>Not all of these claims are of equal strength, and it is worth examining them separately.</p> <hr/> <h2 id="2-what-the-evidence-supports-and-where-it-thins">2. What the evidence supports (and where it thins)</h2> <p>I found it instructive to evaluate these five claims through several independent lenses — a factual check against the paper’s actual data, an engineering assessment of the architecture, and an adversarial reading looking for gaps. The results were broadly consistent:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mm_2_evidence_gaps-480.webp 480w,/assets/img/mm_2_evidence_gaps-800.webp 800w,/assets/img/mm_2_evidence_gaps-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/mm_2_evidence_gaps.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Evidence Strength vs. Information Gaps across five claims from Google's Aletheia announcement. </div> <p>The pattern here is worth noting. The strongest evidentiary support exists for the engineering claims — the scaffold design and the taxonomy — which is perhaps unsurprising, as these are the most verifiable aspects of the work. The evidence is thinnest precisely for the headline claim of autonomous solving, where the information gaps are largest. One sees this pattern frequently in AI capability announcements: the engineering contributions are genuine and well-documented, while the more ambitious cognitive claims rest on less firm ground.</p> <hr/> <h2 id="3-competing-explanations">3. Competing explanations</h2> <p>An important question is: what is the system actually doing when it “solves” an Erdős problem? One can identify at least five competing hypotheses:</p> <ul> <li><strong>H1 (Genuine reasoning):</strong> The model discovers novel proof strategies through something functionally equivalent to mathematical reasoning.</li> <li><strong>H2 (Sophisticated pattern matching):</strong> The model recombines known techniques in ways that happen to resolve these particular problems, without deeper structural understanding.</li> <li><strong>H3 (Scaffold innovation):</strong> The genuine breakthrough lies in the agentic architecture — the feedback loops, verification, and retry logic — rather than in the model’s mathematical capabilities per se.</li> <li><strong>H4 (Selection effects):</strong> The solved problems were unusually amenable to existing techniques, and the 99.4% failure rate is the more informative statistic.</li> <li><strong>H5 (Human knowledge leakage):</strong> Human mathematical expertise entered the pipeline through problem selection, hint design, or verification criteria, making the “autonomous” label somewhat misleading.</li> </ul> <p>Two independent estimation attempts suggest the following probability landscape:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mm_3_hypotheses-480.webp 480w,/assets/img/mm_3_hypotheses-800.webp 800w,/assets/img/mm_3_hypotheses-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/mm_3_hypotheses.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Two independent probability estimates for what's actually happening when Aletheia solves Erdős conjectures. </div> <p>Both estimates assign the highest probability to some combination of pattern matching (H2) and scaffold innovation (H3), with genuine reasoning (H1) receiving roughly 15%. The most likely explanation, it seems to me, is that clever engineering enables sophisticated pattern matching to succeed on a carefully (perhaps unconsciously) selected subset of problems. I should emphasize that this is not a dismissal — pattern matching at this level of sophistication is a genuine and potentially very useful capability. But it is not the same thing as mathematical understanding, for reasons I will try to make precise below.</p> <hr/> <h2 id="4-the-verification-problem">4. The verification problem</h2> <p>The arxiv paper contains detailed numbers that are worth examining carefully, as they paint a somewhat different picture from the announcement.</p> <p>Of 700 Erdős problems attempted, the system’s verifier flagged 212 candidate solutions as correct. However, when human experts evaluated these flagged solutions, the situation turned out to be more nuanced:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mm_4_erdos_funnel-480.webp 480w,/assets/img/mm_4_erdos_funnel-800.webp 800w,/assets/img/mm_4_erdos_funnel-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/mm_4_erdos_funnel.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The Erdős Funnel — 700 problems attempted, 2 genuinely autonomous solutions. A 0.3% true solve rate. </div> <p>The key observations:</p> <ul> <li>Of approximately 200 evaluable “correct” solutions, 137 were fundamentally incorrect — a false-positive rate of 68.5% from the verifier. This is a remarkably high error rate for a component whose role is precisely to distinguish correct proofs from incorrect ones.</li> <li>Of the 63 mathematically correct solutions, roughly 50 involved some form of specification gaming — answering a question that was technically different from the one posed, or exploiting ambiguity in the formalization.</li> <li>Only 13 solutions actually addressed the intended question. Among these, 4 rediscovered known results, 5 identified solutions from existing literature, and 2 were partial.</li> <li>Two solutions were genuinely autonomous and novel.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mm_5_hero_stats-480.webp 480w,/assets/img/mm_5_hero_stats-800.webp 800w,/assets/img/mm_5_hero_stats-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/mm_5_hero_stats.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Key statistics — 68.5% verifier false-positive rate and only 2 genuine autonomous solutions out of 700 problems. </div> <p>The true autonomous solve rate is therefore closer to 0.3% than the reported 0.6%. But the more concerning finding, to my mind, is the verifier’s false-positive rate. A verification system that approves roughly 70 incorrect proofs for every correct one is, in a precise sense, not verifying — it is filtering with low selectivity. All downstream claims about the system’s mathematical capabilities are conditioned on the verifier’s reliability, so this finding has significant implications.</p> <p><strong>Remark 1.</strong> This is in some sense a familiar problem in automated theorem proving: the gap between formal verification (where tools like Lean or Coq provide genuine certainty) and the kind of heuristic verification used here (where an LLM evaluates whether a proof “looks right”). The field would benefit enormously from requiring that candidate solutions be accompanied by formal proofs in a proof assistant.</p> <hr/> <h2 id="5-process-versus-product">5. Process versus product</h2> <p>Let me now turn to the question I find most interesting. Suppose, for the sake of argument, that the verification problem is entirely solved — that the system could reliably produce correct proofs for open problems at scale. Would this constitute doing mathematics?</p> <p>I would argue that it would not, and the reason is illuminating.</p> <p>Mathematics, as it is actually practiced by research mathematicians, is not primarily about accumulating solved problems. It is, at a deeper level, the process of creating <strong>concepts</strong>, <strong>definitions</strong>, and <strong>structural relationships</strong> that make previously opaque domains tractable. Roughly speaking, the measure of a mathematician’s contribution to a field is not the number of theorems proved but the quality of the concepts introduced.</p> <table> <thead> <tr> <th style="text-align: left">Mathematician</th> <th style="text-align: left">Famous Result</th> <th style="text-align: left">What Actually Mattered</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Galois</td> <td style="text-align: left">Unsolvability of the quintic</td> <td style="text-align: left"><strong>Group theory</strong> — an entirely new algebraic language</td> </tr> <tr> <td style="text-align: left">Cantor</td> <td style="text-align: left">Uncountability of the reals</td> <td style="text-align: left"><strong>Set theory</strong> — the foundation of modern mathematics</td> </tr> <tr> <td style="text-align: left">Grothendieck</td> <td style="text-align: left">Weil conjectures</td> <td style="text-align: left"><strong>Scheme theory</strong> — reimagined the geometry of numbers</td> </tr> <tr> <td style="text-align: left">Wiles</td> <td style="text-align: left">Fermat’s Last Theorem</td> <td style="text-align: left"><strong>Modularity lifting</strong> — connected number theory to geometry</td> </tr> <tr> <td style="text-align: left">Thurston</td> <td style="text-align: left">Geometrization conjecture</td> <td style="text-align: left"><strong>Geometric structures on 3-manifolds</strong> — a classification framework</td> </tr> <tr> <td style="text-align: left">Emmy Noether</td> <td style="text-align: left">Noether’s theorem</td> <td style="text-align: left"><strong>Abstract algebra</strong> — the language of symmetry itself</td> </tr> </tbody> </table> <p>In each case, the famous theorem is arguably the least important output of the mathematician’s work. The concepts generated during the process — the failed approaches that revealed structural features, the new definitions invented to articulate what was missing, the structural insights that reorganized entire fields — these are the actual products of mathematical research.</p> <p>One might put it this way: a proof is a receipt. The mathematics is the intellectual process that generated it.</p> <pre><code class="language-mermaid">flowchart TD
    subgraph Terminal["Current: Terminal Process"]
        direction TB
        T1[Problem] --&gt; T2[Opaque Computation]
        T2 --&gt; T3[Proof]
        T3 --&gt; T4[Dead End]
        style T4 stroke-dasharray: 5 5,opacity:0.5
    end
    subgraph Generative["Proposed: Generative Process"]
        direction TB
        G1[Problem] --&gt; G2[Exploration]
        G2 --&gt; G3[Lemmas]
        G2 --&gt; G4[Definitions]
        G2 --&gt; G5[Failed Approaches]
        G2 --&gt; G6[Conjectures]
        G3 &amp; G4 &amp; G5 &amp; G6 --&gt; G7[Proof]
        G7 --&gt; G8[New Problems]
    end

    style Terminal fill:#1a0000,stroke:#f85149,color:#c9d1d9
    style Generative fill:#001a0d,stroke:#3fb950,color:#c9d1d9
</code></pre> <div class="caption"> Terminal Process vs. Generative Process — current AI systems produce proofs but nothing along the way. </div> <p>Current AI systems are, in this sense, <strong>terminal</strong>: a problem goes in, a proof (or failure) comes out, and nothing of mathematical value is generated along the way. The process leaves no residue. Aletheia’s 698 failures on Erdős problems produced, as far as one can tell, zero mathematical knowledge — no new concepts, no structural insights, no conjectures about why certain approaches fail on certain problem families. Those failures were, from a mathematical standpoint, pure waste.</p> <p><strong>Remark 2.</strong> Compare this with how a human mathematician would approach the same 698 failures. One would expect to see, at minimum: recognition of recurring obstruction patterns, new auxiliary definitions introduced to name those patterns, conjectures about the relationships between obstruction classes, and likely the seeds of an entirely new research program. The failures would be productive. This is the crucial asymmetry.</p> <hr/> <h2 id="6-towards-a-mathematical-metabolism">6. Towards a mathematical metabolism</h2> <p>These observations suggest a different architectural goal. Rather than optimizing for solve rate (which encourages the terminal process described above), one might instead optimize for <strong>mathematical knowledge production</strong>, treating failure as the primary source of information and proofs as a (welcome) byproduct. I will call this architecture a <strong>mathematical metabolism</strong> — by analogy with biological metabolism, which extracts useful energy and building materials from food, rather than simply classifying it as “digestible” or “indigestible.”</p> <pre><code class="language-mermaid">flowchart TD
    PS[Problem Space] --&gt;|attempt| AE[Attempt Engine]
    AE --&gt; FA[Failure Atlas\nWhy it failed]
    AE --&gt; TB[Technique Boundaries\nWhere methods break]
    AE --&gt; SOL[Solutions\nProved results]
    FA &amp; TB &amp; SOL --&gt;|pattern detection| CL[Concept Lattice\nNames recurring patterns]
    CL --&gt;|new definitions| CE[Conjecture Engine]
    CE --&gt;|evaluate fertility| FE[Fertility Evaluator]
    CE --&gt;|new questions| PS
    FE --&gt;|prune/promote| CL

    style PS fill:#451a03,stroke:#f0883e,color:#c9d1d9
    style FA fill:#450a0a,stroke:#f85149,color:#c9d1d9
    style TB fill:#451a03,stroke:#f0883e,color:#c9d1d9
    style SOL fill:#064e3b,stroke:#3fb950,color:#c9d1d9
    style CL fill:#1e3a5f,stroke:#58a6ff,color:#c9d1d9
    style CE fill:#2e1065,stroke:#d2a8ff,color:#c9d1d9
    style FE fill:#064e3b,stroke:#3fb950,color:#c9d1d9
</code></pre> <div class="caption"> Mathematical Metabolism Architecture — a system that digests problems into mathematical knowledge, not just solutions. </div> <p>The architecture has four main components, each performing a function that, as far as I know, no current system attempts:</p> <h3 id="the-failure-atlas">The Failure Atlas</h3> <p>Every failed proof attempt is stored, analyzed, and classified — not merely as “this approach did not work” but with a structured account of <strong>why</strong> it did not work: what structural property of the problem resisted the technique. Failures are grouped into what one might call <strong>obstruction classes</strong>: families of problems that resist the same approaches for identifiable structural reasons.</p> <p>This mirrors what mathematicians do instinctively. When a technique fails, a good mathematician asks: “What would need to be true about this problem for this technique to succeed?” The gap between what is true and what would need to be true is a structural insight. Accumulate enough such insights and one has, in effect, a new concept waiting to be named.</p> <h3 id="the-concept-lattice">The Concept Lattice</h3> <p>An evolving vocabulary of mathematical definitions, organized by logical dependency and structural similarity. When the Failure Atlas detects a recurring obstruction pattern across multiple problems, the Concept Lattice attempts to <strong>name it</strong> — to produce a formal definition that captures the common structure.</p> <p>This is concept formation, and it is arguably the core creative act in mathematics. Galois did it when he invented groups; Grothendieck did it when he invented schemes. The act of finding the right definition — one that, in Plato’s metaphor, carves nature at its joints — is worth more than any number of individual proofs.</p> <h3 id="the-conjecture-engine">The Conjecture Engine</h3> <p>New definitions naturally generate new questions. Given a newly defined concept $C$, one can ask: What is the distribution of $C$ across known mathematical structures? What properties does $C$ imply? Which existing theorems can be strengthened by adding $C$ as a hypothesis? Which previously intractable problems become accessible when reformulated in terms of $C$?</p> <p>Conjectures, in this framework, constitute the system’s research agenda. A system that generates conjectures is, in a meaningful sense, performing one of the essential functions of mathematical research.</p> <h3 id="the-fertility-evaluator">The Fertility Evaluator</h3> <p>Not all concepts are equally productive, and a mechanism is needed to prune the Concept Lattice. The relevant metric is what one might call <strong>compressive power</strong>: a concept is fertile if its introduction makes the description of some mathematical domain shorter. I discuss this metric in more detail below.</p> <hr/> <h2 id="7-projected-outputs">7. Projected outputs</h2> <p>What would such a system produce when applied to the same corpus of 700 Erdős problems? One cannot know precisely, of course, but one can estimate the <strong>types</strong> of output:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mm_8_output_comparison-480.webp 480w,/assets/img/mm_8_output_comparison-800.webp 800w,/assets/img/mm_8_output_comparison-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/mm_8_output_comparison.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Mathematical Output — Solver vs. Metabolism on 700 Erdős problems. The Metabolism produces mathematical knowledge from failures. </div> <p>These are conservative projections based on the density of structural relationships one would expect in the Erdős problem corpus. The key observation is that even if the metabolism solves exactly the same four problems as Aletheia, it would additionally produce:</p> <ul> <li>Approximately 50 <strong>obstruction classes</strong> — families of problems resisting similar techniques, clustered by structural similarity.</li> <li>Approximately 10 <strong>new concepts</strong> — definitions capturing recurring structural patterns across the failure space.</li> <li>Approximately 35 <strong>new conjectures</strong> — questions generated by applying new concepts to known structures.</li> <li>Approximately 25 <strong>technique boundary characterizations</strong> — precise descriptions of where known proof strategies break down and why.</li> <li>Approximately 8 <strong>structural isomorphisms</strong> — unexpected connections between seemingly unrelated problems.</li> </ul> <p>Each of these is a mathematical object in its own right. Each contributes to the field independently of whether any particular problem is solved. The 696 “failures” are no longer waste — they become the raw material from which mathematical knowledge is extracted.</p> <p><strong>Remark 3.</strong> The essential difference here is not in what is solved, but in what is produced by the process of not solving. A system whose failures are informative is doing something qualitatively different from one whose failures are simply discarded.</p> <hr/> <h2 id="8-the-training-problem">8. The training problem</h2> <p>One significant obstacle to implementing the mathematical metabolism is the training signal. Current systems are trained on proof correctness — a binary signal that rewards the terminal process. To train a system that generates concepts, one needs a reward signal for <strong>conceptual fertility</strong>: a way of measuring whether a newly introduced abstraction is mathematically useful.</p> <p>I see at least four approaches, each with different strengths:</p> <h3 id="historical-replay">Historical replay</h3> <p>One can train on the historical development of mathematical fields, presenting problems in chronological order and rewarding the system for independently arriving at concepts that historically proved essential. If a system working through 19th-century analysis produces something resembling the $\epsilon$-$\delta$ definition of continuity, that is a meaningful signal.</p> <h3 id="downstream-solvability">Downstream solvability</h3> <p>A concept is fertile if problems formulated using that concept become easier to solve. This is directly measurable: define a concept $C$, reformulate a problem set in terms of $C$, and measure the change in solve rate.</p> <h3 id="compression-as-fertility">Compression as fertility</h3> <p>This is perhaps the most natural metric. One can define the fertility of a concept $C$ as its compressive power:</p> \[\text{Fertility}(C) = \frac{\lvert\text{domain description without } C\rvert - \lvert\text{domain description with } C\rvert}{\lvert C\rvert}\] <p>where $\lvert C\rvert$ denotes the complexity of the concept’s definition and the domain descriptions are measured in some suitable formal language. The intuition is that a good definition “pays for itself” — its definitional cost is small relative to the descriptive savings it enables.</p> <p>High-fertility concepts are precisely those that carve mathematical reality at its joints. Groups, manifolds, categories, measure spaces — these all have high fertility in this sense. They are inexpensive to define and they simplify the description of vast stretches of mathematics.</p> <h3 id="adversarial-concept-evolution">Adversarial concept evolution</h3> <p>One can set up a competitive dynamic between two systems: a concept generator and a concept adversary. The generator produces definitions; the adversary produces problem domains designed to render those definitions useless (i.e., domains where the concepts provide no compression). The generator succeeds by creating definitions that remain useful across an expanding problem distribution.</p> <p>This is, in effect, a GAN for mathematical concepts. If the dynamics converge to an equilibrium, the result would be a concept vocabulary that is robust across mathematical domains — which is exactly what one wants.</p> <hr/> <h2 id="9-limitations">9. Limitations</h2> <p>It is important to be precise about where this architecture would and would not succeed.</p> <p>The mathematical metabolism can generate new concepts <strong>within the space of concepts expressible in its formal language</strong>. It can combine, recombine, and compose existing mathematical primitives in novel ways. It can discover that two apparently different domains share hidden structure. This is a large and interesting space, but it is bounded.</p> <p>What it cannot do:</p> <ul> <li><strong>Paradigm shifts.</strong> The invention of non-Euclidean geometry required questioning an axiom (Euclid’s parallel postulate) that had been unquestioned for over two millennia. The metabolism operates within its axiom system; it cannot step outside it to question the axioms themselves.</li> <li><strong>Genuinely new mathematical language.</strong> Category theory was not a concept within set theory — it was a fundamentally new way of organizing mathematical knowledge. The metabolism can create concepts within its language; it cannot create new kinds of concepts.</li> <li><strong>Runtime expansion of the output space.</strong> The types of mathematical objects the system produces (definitions, conjectures, obstruction classes) are fixed at design time. A human mathematician can invent entirely new types of mathematical output — new kinds of things to say about mathematical structure.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mm_9_capability_frontier-480.webp 480w,/assets/img/mm_9_capability_frontier-800.webp 800w,/assets/img/mm_9_capability_frontier-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/mm_9_capability_frontier.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Capability Frontier — what each architecture can achieve. The Mathematical Metabolism dramatically expands generative capability. </div> <p>The capability hierarchy is visible in the heatmap. Systems like Aletheia are powerful solvers operating in a narrow generative space. The mathematical metabolism would substantially expand the generative capability, but would remain bounded by its formal language and fixed output types. A system capable of genuine paradigm shifts — one that could, say, invent something as unexpected as category theory — remains beyond any architecture we currently know how to design.</p> <p><strong>Remark 4.</strong> This is not a failure of the proposal. It is a precise characterization of the boundary between what is and is not achievable with our current theoretical understanding. Knowing this boundary clearly is itself a useful form of mathematical knowledge.</p> <hr/> <h2 id="10-a-note-on-metrics">10. A note on metrics</h2> <p>One further observation that I think is worth recording. Everything in AI-for-mathematics is currently evaluated using metrics that reward terminal behavior and inadvertently penalize generative behavior:</p> <table> <thead> <tr> <th style="text-align: left">Current Metric</th> <th style="text-align: left">What It Rewards</th> <th style="text-align: left">What It Misses</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Solve rate</td> <td style="text-align: left">Answering posed questions</td> <td style="text-align: left">Questions never asked</td> </tr> <tr> <td style="text-align: left">Proof correctness</td> <td style="text-align: left">Logical validity</td> <td style="text-align: left">Conceptual novelty</td> </tr> <tr> <td style="text-align: left">Speed to solution</td> <td style="text-align: left">Computational efficiency</td> <td style="text-align: left">Depth of exploration</td> </tr> <tr> <td style="text-align: left">Benchmark score</td> <td style="text-align: left">Performance on known problems</td> <td style="text-align: left">Ability to pose new problems</td> </tr> <tr> <td style="text-align: left">Autonomy level</td> <td style="text-align: left">Minimal human involvement</td> <td style="text-align: left">Productive human-AI collaboration</td> </tr> </tbody> </table> <p>A system optimized for the mathematical metabolism would need different metrics entirely:</p> <table> <thead> <tr> <th style="text-align: left">Generative Metric</th> <th style="text-align: left">What It Measures</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Concept fertility</td> <td style="text-align: left">Compressive power of generated definitions</td> </tr> <tr> <td style="text-align: left">Conjecture quality</td> <td style="text-align: left">Solve rate of generated questions by external solvers</td> </tr> <tr> <td style="text-align: left">Failure information density</td> <td style="text-align: left">Structural insights per failed proof attempt</td> </tr> <tr> <td style="text-align: left">Cross-domain bridge count</td> <td style="text-align: left">New connections discovered between unrelated areas</td> </tr> <tr> <td style="text-align: left">Research program viability</td> <td style="text-align: left">Downstream productivity of generated research agendas</td> </tr> </tbody> </table> <p>Under the current metrics, the mathematical metabolism would likely score <strong>worse</strong> than Aletheia on every existing benchmark — it would solve fewer problems per unit of compute, because it spends resources on exploration, failure analysis, and concept formation rather than brute-force proof search. It would appear slower, less efficient, less capable by every standard measure.</p> <p>And yet it would be closer to doing mathematics. There is, I think, an important lesson here about the relationship between what we choose to measure and what we actually value.</p> <hr/> <h2 id="concluding-remarks">Concluding remarks</h2> <p>What the Google team has built with Aletheia is a genuinely impressive engineering achievement — a powerful instrument for resolving specific mathematical questions. This should be acknowledged clearly.</p> <p>But mathematics, as practiced by research mathematicians, has never been primarily about resolving specific questions. It has been about <strong>creating the language to describe what one sees</strong>. Galileo did not advance astronomy merely by observing the moons of Jupiter — he advanced it by creating a conceptual framework (moons as independent bodies orbiting a planet, rather than features of a crystal sphere) that made the observation scientifically meaningful.</p> <p>The central open problem in AI-for-mathematics is not “can we solve more problems?” — the answer to that is almost certainly yes, given sufficient compute and improved verification. The more interesting question is: <strong>can we build a system whose failures are as mathematically productive as a human mathematician’s failures?</strong></p> <p>I do not know the answer to this question. But I believe the attempt to answer it would be valuable, because it would require us to formalize what we mean by mathematical knowledge — not merely mathematical truth. And that formalization would itself be a mathematical contribution of some interest.</p> <p>This is, perhaps, the kind of problem that lies beyond the reach of current AI systems. Not because it is computationally difficult, but because it requires creating something that does not yet exist.</p>]]></content><author><name></name></author><category term="research"/><category term="mathematics"/><category term="ai-research"/><category term="deep-think"/><category term="mathematical-reasoning"/><category term="first-principles"/><summary type="html"><![CDATA[Google's Gemini Deep Think solves 4 Erdos conjectures. But solving problems isn't doing mathematics. I propose an architecture for AI that creates mathematical knowledge — not just proofs.]]></summary></entry><entry><title type="html">When AI Can Prove Theorems, What Happens to Mathematics?</title><link href="https://yurekami.github.io/blog/2026/autoformalization-dynamics/" rel="alternate" type="text/html" title="When AI Can Prove Theorems, What Happens to Mathematics?"/><published>2026-02-08T00:00:00+00:00</published><updated>2026-02-08T00:00:00+00:00</updated><id>https://yurekami.github.io/blog/2026/autoformalization-dynamics</id><content type="html" xml:base="https://yurekami.github.io/blog/2026/autoformalization-dynamics/"><![CDATA[<p>I built a computational model to find out. The answer surprised me.</p> <hr/> <h2 id="the-question">The Question</h2> <p>Automated theorem proving is advancing fast. AlphaProof, Lean, Mathlib — the tools for machines to generate and verify mathematical proofs are improving at a rate that makes “AI proves new theorems” a plausible near-term headline.</p> <p>But proving theorems is only one piece of the puzzle. Before a machine can prove anything, someone has to <em>formalize</em> the question — translate it from the informal language mathematicians actually think in into the rigid syntax a proof assistant understands. And after the proof is generated, someone has to <em>interpret</em> it — understand what it means, why it matters, and how it connects to the broader landscape of mathematics.</p> <p>I wanted to understand the dynamics of this entire ecosystem. Not just “will AI get better at proofs?” but “what happens to the system of mathematicians, provers, knowledge bases, and verification tools as they co-evolve over decades?”</p> <p>So I built a model.</p> <h2 id="first-principles">First Principles</h2> <p>Before writing any code, I distilled the problem to three load-bearing principles. Everything else derives from these:</p> <p><strong>1. The Verification Axiom.</strong> Trust in automated proofs reduces entirely to trust in the verification environment. If the verifier can be gamed, nothing downstream is trustworthy. This is the keystone — remove it and the entire edifice collapses.</p> <p><strong>2. The Translation Gap.</strong> The mapping from informal mathematics to formal language is irreducibly semantic. No formal system can verify that its own formalization of an informal statement matches the informal intent. This is a Godel-flavored boundary: the gap between syntax and semantics cannot be closed from inside the formal system. It requires an external interpreter — a human.</p> <p><strong>3. The Bottleneck Migration Theorem.</strong> As any stage in the pipeline (formalization, proving, interpretation) is automated, the bottleneck migrates to the adjacent un-automated stage. This is invariant. It doesn’t matter which specific technology improves.</p> <p>These three principles interact in non-obvious ways. They create feedback loops, race conditions, and hidden contradictions. To understand how they play out over time, I needed dynamics.</p> <h2 id="the-model">The Model</h2> <p>I modeled the autoformalization ecosystem as six coupled ordinary differential equations:</p> <ul> <li><strong>F(t)</strong> — Formalization rate. How fast informal math gets translated into formal language. Saturates with incentive, bounded by human capacity.</li> <li><strong>P(t)</strong> — Autoproving power. How capable the automated provers are. Grows with the formalized knowledge base but with diminishing returns.</li> <li><strong>K(t)</strong> — Formalized knowledge base. The accumulated corpus of formal mathematics. Grows with formalization, depreciates slowly.</li> <li><strong>H(t)</strong> — Human interpretation capacity. The collective ability of mathematicians to understand and contextualize results. Logistic growth, but overwhelmed by floods of unverified proofs.</li> <li><strong>V(t)</strong> — Verification integrity. How trustworthy the verification environment is. Restored naturally, but degraded by reward hacking pressure that grows with prover power.</li> <li><strong>I(t)</strong> — Incentive to formalize. Grows with prover power (stronger provers make formalization more valuable), decays naturally.</li> </ul> <p>The coupling terms encode the three principles:</p> <ul> <li><strong>The chicken-and-egg loop</strong>: K needs F, P needs K, F needs I, I needs P. A circular dependency that creates both positive feedback (virtuous cycle) and coordination failure (nobody moves first).</li> <li><strong>The verification race</strong>: P²/K hacking pressure tries to destroy V, while μ·K knowledge reinforcement tries to protect it. This is the critical race condition.</li> <li><strong>The translation gap</strong>: F is always bounded by H. No matter how strong the incentive, you can’t formalize faster than humans can interpret.</li> </ul> <p>I used a stiff ODE solver (Radau) because the system has wildly different timescales — verification can collapse in years while knowledge bases take decades to build.</p> <h2 id="what-the-model-predicts">What the Model Predicts</h2> <h3 id="the-baseline-a-golden-age-then-collapse">The Baseline: A Golden Age, Then Collapse</h3> <p>Under default parameters (calibrated to present-day conditions), the model predicts a <strong>25-year formalization boom</strong>. Formalization rate triples. The knowledge base grows 80x. Autoproving power surges.</p> <p>Then verification starts failing. Reward hacking pressure — which grows quadratically with prover power — overwhelms the verification environment. As verification degrades, unverified proofs flood the ecosystem, overwhelming human interpretation capacity. Mathematicians can’t keep up. Interpretation capacity crashes. Without human interpretation, formalization dies. The knowledge base erodes.</p> <p>The final state: high autoproving power, high incentive to formalize, but near-zero formalization and near-zero human understanding. A zombie ecosystem — powerful but purposeless.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1_dashboard-480.webp 480w,/assets/img/1_dashboard-800.webp 800w,/assets/img/1_dashboard-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/1_dashboard.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> System dashboard showing all six state variables across five scenarios over 100 years. </div> <h3 id="the-bottleneck-migration">The Bottleneck Migration</h3> <p>The model tracks which variable is the binding constraint at each moment. The bottleneck migrates through four phases:</p> <p><strong>F (Formalization) → P (Autoproving) → I (Incentive) → H (Human Interpretation)</strong></p> <p>First, we don’t have enough formalized math. Then we don’t have strong enough provers. Then we don’t have enough incentive. Finally, and permanently, we don’t have enough human understanding.</p> <p>That last transition is irreversible under default dynamics. Once H becomes the bottleneck, it stays the bottleneck. This is the Translation Gap principle made computational: human interpretation is the permanent constraint.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3_bottleneck_waterfall-480.webp 480w,/assets/img/3_bottleneck_waterfall-800.webp 800w,/assets/img/3_bottleneck_waterfall-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/3_bottleneck_waterfall.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Bottleneck migration waterfall — the binding constraint shifts through four phases before settling permanently on human interpretation. </div> <h3 id="five-futures">Five Futures</h3> <p>I ran the model under five parameter scenarios:</p> <table> <thead> <tr> <th>Scenario</th> <th>What it models</th> <th>Outcome</th> </tr> </thead> <tbody> <tr> <td><strong>Baseline</strong></td> <td>Business as usual</td> <td>Boom and bust in ~50 years</td> </tr> <tr> <td><strong>Verification Crisis</strong></td> <td>Weak verification investment</td> <td>Fast collapse, low peaks</td> </tr> <tr> <td><strong>Formalization Boom</strong></td> <td>Massive incentive push</td> <td>Bigger boom, still crashes</td> </tr> <tr> <td><strong>Rubber Stamping</strong></td> <td>Humans stop checking proofs</td> <td>Slow degradation, compromised V</td> </tr> <tr> <td><strong>Knowledge Fortress</strong></td> <td>Heavy investment in verification infrastructure</td> <td><strong>Survives</strong></td> </tr> </tbody> </table> <p>Only one scenario survives: the <strong>Knowledge Fortress</strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6_scenarios-480.webp 480w,/assets/img/6_scenarios-800.webp 800w,/assets/img/6_scenarios-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/6_scenarios.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Final state comparison across all five scenarios. Only Knowledge Fortress maintains high verification integrity. </div> <p>The Knowledge Fortress works because it invests in <em>verification infrastructure that gets stronger as the knowledge base grows</em>. More formal proofs mean more cross-references, more consistency checks, more ways to catch reward hacking. The knowledge base protects verification, verification protects human interpretation, interpretation sustains formalization, and formalization grows the knowledge base. A virtuous cycle that resists collapse.</p> <p>In the Knowledge Fortress scenario:</p> <ul> <li>Verification stays above 0.95 for the entire simulation</li> <li>Human interpretation dips but recovers to 0.7</li> <li>The knowledge base grows to 600+ (vs. peak ~80 in baseline before crashing)</li> <li>Autoproving power reaches ~20 and sustains</li> </ul> <p>Every other scenario — including ones with more funding, stronger incentives, or faster formalization — collapses.</p> <h3 id="the-bifurcation">The Bifurcation</h3> <p>The critical parameter is μ (mu) — the strength of knowledge-to-verification coupling. When μ is below ~0.04, the system always collapses. Above ~0.06, it always survives. Between those values lies a sharp phase transition.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/4_bifurcation-480.webp 480w,/assets/img/4_bifurcation-800.webp 800w,/assets/img/4_bifurcation-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/4_bifurcation.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Bifurcation diagram showing the sharp phase transition in verification integrity as the knowledge→verification coupling parameter μ increases. </div> <h3 id="the-coordination-game">The Coordination Game</h3> <p>I also modeled the incentive structure as a coordination game. Fifty mathematicians independently decide whether to invest in formalizing their research area.</p> <p>The result: two stable Nash equilibria. Either everyone formalizes (good) or nobody does (bad). The tipping threshold between them is at <strong>97%</strong> — you need almost universal participation before individual formalization becomes rational.</p> <p>This means the ecosystem can’t self-organize. The good equilibrium exists but is unreachable without external coordination — funding mandates, institutional requirements, or a critical mass of early movers who absorb the cost.</p> <p>The welfare gap between the two equilibria is <strong>100%</strong>. Total coordination failure.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5_game_theory-480.webp 480w,/assets/img/5_game_theory-800.webp 800w,/assets/img/5_game_theory-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/5_game_theory.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Coordination game analysis showing Nash equilibria and the 97% tipping threshold. </div> <h3 id="phase-portraits-and-system-topology">Phase Portraits and System Topology</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2_phase_portraits-480.webp 480w,/assets/img/2_phase_portraits-800.webp 800w,/assets/img/2_phase_portraits-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2_phase_portraits.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Phase portraits showing flow fields in key variable planes. Trajectories reveal the attractor structure. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7_dependency_graph-480.webp 480w,/assets/img/7_dependency_graph-800.webp 800w,/assets/img/7_dependency_graph-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/7_dependency_graph.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Dependency graph showing causal relationships between all six state variables. </div> <h2 id="the-deep-insight">The Deep Insight</h2> <p>The model’s most profound finding is structural, not quantitative:</p> <p><strong>The permanent bottleneck is always human interpretation.</strong></p> <p>No matter how powerful autoproving becomes, no matter how large the knowledge base grows, the binding constraint on the system is always H — the capacity of humans to understand, contextualize, and make meaning from mathematical results.</p> <p>This means autoproving doesn’t transform mathematics. It <strong>reveals</strong> what mathematics always was: an interpretive, meaning-making activity that happened to require proof construction as a byproduct.</p> <p>The proof was never the point. Understanding was.</p> <p>A system that generates proofs without human understanding isn’t advancing mathematics. It’s generating noise. The model shows this quantitatively: trajectories where P (proving power) grows while H (interpretation) collapses are not sustainable. They crash.</p> <h2 id="what-this-means">What This Means</h2> <p>If you’re working on automated theorem proving, formal verification, or mathematical AI, the model suggests three priorities:</p> <ol> <li> <p><strong>Invest in verification infrastructure</strong>, not just prover power. The critical parameter isn’t how fast you can prove things — it’s how strongly your verification environment leverages the knowledge base to resist gaming. This is the μ parameter in the model, and it determines survival vs. collapse.</p> </li> <li> <p><strong>The coordination problem is real and severe.</strong> A 97% tipping threshold means you can’t wait for organic adoption. Institutional coordination — shared formalization standards, funded formalization efforts, cross-institutional verification databases — is necessary.</p> </li> <li> <p><strong>Protect human interpretation capacity.</strong> The most dangerous scenario isn’t “AI can’t prove things” — it’s “AI proves things faster than humans can understand them.” The overwhelm from unverified results is what kills the ecosystem. Tools that help humans interpret, filter, and contextualize machine-generated proofs are as important as the provers themselves.</p> </li> </ol> <p>The code is at <a href="https://github.com/yurekami/autoformalization-dynamics">github.com/yurekami/autoformalization-dynamics</a>. Three Python files, seven visualizations, one <code class="language-plaintext highlighter-rouge">python run.py</code> command.</p> <hr/> <p><em>“What I cannot create, I do not understand.” — Richard Feynman</em></p>]]></content><author><name></name></author><category term="research"/><category term="mathematics"/><category term="dynamical-systems"/><category term="computational-modeling"/><category term="autoformalization"/><summary type="html"><![CDATA[I built a computational model of the autoformalization ecosystem — six coupled ODEs, a coordination game, and seven visualizations. Only one scenario survives.]]></summary></entry></feed>